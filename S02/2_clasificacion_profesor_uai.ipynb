{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src='images/small-uai.jpeg'style=\"width: 300px;\">\n",
    "</center>\n",
    "\n",
    "# Laboratorio S02: Clasificación Lineal y Redes Neuronales\n",
    "\n",
    "## _Deep learning_\n",
    "   \n",
    "<center>\n",
    "    <img src='images/clasificacion-lineal.png'style=\"width: 400px;\">\n",
    "    <sub><sup>http://eenube.com/images/sampledata/moon_reg_log.png</sup></sub> \n",
    "</center>\n",
    "\n",
    "**Profesor**: Dr. Juan Bekios Calfa\n",
    "\n",
    "**Grado**: MIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vCDOgrxA6qM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Laboratorio 02: Clasificación Lineal y Redes Neuronales\n",
    "\n",
    "Objetivo:\n",
    "\n",
    "1.   Implementar una regresión logística\n",
    "2.   Implementar una red neuronal simple como **regresor**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vCDOgrxA6qM",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Regresión logística\n",
    "\n",
    "Clasificación binaria utilizando regresión logística. Implemntado en Pytorch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XH2wceWdb5tu",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Librerías\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import datasets # Base de datos que vamos a utilizar\n",
    "from sklearn.preprocessing import StandardScaler # Escalar los datos de entrada\n",
    "from sklearn.model_selection import train_test_split # Crear el conjunto de entrenamiento y pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XH2wceWdb5tu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# 0) Preparar los datos\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# Escalar\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) # Entrenar\n",
    "#X_train = sc.transform(X_train) # Conjunto de entrenamiento va quedar escalado\n",
    "X_test = sc.transform(X_test) # Conjunto de prueba escalado\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XH2wceWdb5tu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Modelo\n",
    "class Model(nn.Module):\n",
    "  # Declarar las partes del modelo\n",
    "  def __init__(self, n_input_features):\n",
    "    super(Model, self).__init__()\n",
    "    self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "  # Calcular la estimacion (x <- vector de entrada)\n",
    "  def forward(self,x):\n",
    "    y_pred = torch.sigmoid(self.linear(x))\n",
    "    return y_pred\n",
    "\n",
    "model = Model(n_features)\n",
    "\n",
    "# 2) Loss y optimizar\n",
    "num_epochs = 100\n",
    "learning_rate = 0.02\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XH2wceWdb5tu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10,, loss = 0.1285\n",
      "epoch: 20,, loss = 0.1259\n",
      "epoch: 30,, loss = 0.1236\n",
      "epoch: 40,, loss = 0.1214\n",
      "epoch: 50,, loss = 0.1193\n",
      "epoch: 60,, loss = 0.1173\n",
      "epoch: 70,, loss = 0.1155\n",
      "epoch: 80,, loss = 0.1138\n",
      "epoch: 90,, loss = 0.1121\n",
      "epoch: 100,, loss = 0.1106\n",
      "Tasa de acierto: 0.9035\n"
     ]
    }
   ],
   "source": [
    "# 3) Ciclo entrenamiento\n",
    "for epoch in range(num_epochs):\n",
    "  # Forward \n",
    "  y_pred = model(X_train)\n",
    "  loss = criterion(y_pred, y_train) # Error\n",
    "\n",
    "  # Calcular gradientes\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  # Cero los gradientes\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  if (epoch+1) % 10 == 0:\n",
    "    print(f'epoch: {epoch+1},, loss = {loss.item():.4f}')\n",
    "\n",
    "# 4) Comparar con el conjunto de pruebas\n",
    "with torch.no_grad():\n",
    "  y_predicted = model(X_test)\n",
    "  y_predicted_cls = y_predicted.round()\n",
    "  acc = y_predicted_cls.eq(y_test).sum() /float(y_test.shape[0])\n",
    "  print(f'Tasa de acierto: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iI3KlsJb6iZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Red neuronal poco profunda\n",
    "\n",
    "Regresión utilizando una red neuronal poca profunda. Implementada en Pytorch.\n",
    "\n",
    "El problema tiene solo **un atributo de entrada** y una **etiquta de salida**.\n",
    "\n",
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TCt0dCPJcLlx",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzsqpvXacL7a",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Definir el modelo neuronal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "w7U8OsCVcPU3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(1, 2, bias=True)\n",
    "    self.fc2 = nn.Linear(2, 1, bias=True)\n",
    "\n",
    "  # Prediccion\n",
    "  def forward(self, x):\n",
    "    x = self.fc2(F.relu(self.fc1(x)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf0LatuzcUPK",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parámetros de optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "za_7uuZXcZO7",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net = Net().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKqsa8dScbH5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Definir una base de datos hipotética"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "Nwqo9XrCce0p",
    "outputId": "be76f833-76ec-4098-cd63-001d9bbbb3dc",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4FuFgz6cotx",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "qLzdRujmcwz6",
    "outputId": "b98f8090-e1e3-4285-b5da-2e221cf038a3",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.4838],\n",
      "        [-0.1446]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.5787,  0.1759], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0662,  0.1834]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.1189], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "DmIGzepLJ64n",
    "outputId": "c582f5a2-c74a-452a-ea89-7e78d601ddfb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.3158]]], device='cuda:0')\n",
      "tensor([[[-1.0171]]])\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1,1,1)).cuda()\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OGGYICF0KWTX",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Dejar los gradientes en cero\n",
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "FsF_eOtBKfNf",
    "outputId": "2c3033a9-6fc8-45dd-f144-b878a83b6d07",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6601]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAxCM66BLHxR",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "IoAdWbhMLLfk",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.4)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Yn3OjqxmMvH9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = [(1,3), (2, 6), (3,9), (4, 12), (5, 15), (6,18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "TbE1gnvJM-2k",
    "outputId": "ead7f65a-65d6-4798-ee13-c1bcc4609fef",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 313.978515625\n",
      "Epoch 20 - loss: 0.08640945702791214\n",
      "Epoch 40 - loss: 0.050383418798446655\n",
      "Epoch 60 - loss: 0.029850633814930916\n",
      "Epoch 80 - loss: 0.018024258315563202\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "  for i, data2 in enumerate(data):\n",
    "    X, Y = iter(data2)\n",
    "    X, Y = Variable(torch.FloatTensor([X]), requires_grad=True).cuda(), Variable(torch.FloatTensor([Y]), requires_grad=False).cuda()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred =  net(X)\n",
    "    output = criterion(y_pred, Y)\n",
    "    output.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  if (epoch % 20 == 0.0):\n",
    "    print('Epoch {} - loss: {}'.format(epoch, output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "Jf3831xcOj6_",
    "outputId": "512be210-ef6d-40cd-81ae-5c720f839a99",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 1.7440],\n",
      "        [-0.3228]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1398, 0.7401], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 1.6861, -0.4506]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0624], device='cuda:0', requires_grad=True)]\n",
      "\n",
      "<class 'torch.Tensor'> torch.Size([2, 1])\n",
      "<class 'torch.Tensor'> torch.Size([2])\n",
      "<class 'torch.Tensor'> torch.Size([1, 2])\n",
      "<class 'torch.Tensor'> torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(list(net.parameters()), end='\\n\\n')\n",
    "\n",
    "# Listar los atributos de los parámetros\n",
    "for param in net.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "2_clasificacion_profesor_uai.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
